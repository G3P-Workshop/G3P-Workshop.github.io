<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>G3P@CVPR25</title>
  <link rel="stylesheet" href="styles.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
</head>

<body>
  <!-- Hero Section -->
  <section class="hero">
    <h1>Global 3D Human Poses (G3P) Workshop</h1>
    <p class="subtitle">CVPR 2025 Workshop</p>
    <p class="details">
      <i class="fa fa-calendar"></i> June 11 (Wed), 2025 &nbsp;
      <i class="fa fa-map-marker"></i> Room 105B, Music City Center, Nashville, Tennessee
    </p>
  </section>

  <!-- Main Content Container -->
  <div class="container">
    <!-- Summary Section -->
    <section id="summary">
      <h2>Summary</h2>
      <p>
        Over the past years, human pose estimation research has achieved remarkable progress—primarily focusing on
        capturing local, camera-centric body poses. Yet real-world applications demand a deeper understanding: one that
        integrates global spatial context and the full trajectories of human movement. In environments as diverse as
        robotics, sports analytics, virtual reality, and autonomous systems, the ability to accurately track and
        interpret human motion on a global scale is becoming increasingly essential.
      </p>
      <p>
        Despite significant advances in deep learning and local pose estimation, methods that consider the complete,
        global context remain underexplored. This gap means that many state-of-the-art solutions, while impressive in
        controlled settings, fall short when applied to complex, dynamic scenarios where understanding motion in world
        coordinates is critical.
      </p>
      <p>
        The Global 3D Human Poses (G3P) workshop is designed to bridge this gap by focusing on innovative techniques
        that incorporate trajectory data into pose estimation. By fostering collaboration among researchers and
        practitioners, the workshop will delve into new methodologies, address emerging challenges, and discuss the
        transformative potential of global pose estimation. Ultimately, the insights and innovations presented here are
        poised to push the boundaries of computer vision and pave the way for more robust, real-world applications in
        interactive systems and beyond.
      </p>
    </section>

    <!-- Speakers Section -->
    <section id="speakers">
      <h2>Speakers</h2>
      <div class="speaker-grid">
        <div class="speaker">
          <img src="assets/imgs/avatar_speaker_michael.jpg" alt="Prof. Michael J. Black">
          <h3>Prof. Michael J. Black</h3>
          <p>(MPI Perceiving Systems)</p>
        </div>
        <div class="speaker">
          <img src="assets/imgs/avatar_speaker_hanbyul.jpg" alt="Prof. Hanbyul Joo">
          <h3>Prof. Hanbyul Joo</h3>
          <p>(Seoul National University)</p>
        </div>
        <div class="speaker">
          <img src="assets/imgs/avatar_speaker_angjoo.jpg" alt="Prof. Angjoo Kanazawa">
          <h3>Prof. Angjoo Kanazawa</h3>
          <p>(UC Berkeley)</p>
        </div>
        <div class="speaker">
          <img src="assets/imgs/avatar_speaker_kris.jpg" alt="Prof. Kris Kitani">
          <h3>Prof. Kris Kitani</h3>
          <p>(Carnegie Mellon University)</p>
        </div>
      </div>
    </section>

    <!-- Schedule Section -->
    <section id="schedule">
      <h2>Schedule</h2>
      <!-- <p><b><em>Note: The schedule is for reference only and is subject to change.</em></b></p> -->
      <table>
        <tr>
          <th>Time</th>
          <th>Event</th>
        </tr>
        <tr>
          <td>08:45 - 09:00</td>
          <td>Welcome &amp; Intro</td>
        </tr>
        <tr>
          <td>09:00 - 09:30</td>
          <td>Invite Talk #1 (Prof. Michael J. Black): Estimating human motion in world coordinates</td>
        </tr>
        <tr>
          <td>09:30 - 10:00</td>
          <td>Invite Talk #2 (Prof. Hanbyul Joo): Understanding 3D Humans in Contextual 3D Spaces</td>
        </tr>
        <tr>
          <td>10:00 - 10:30</td>
          <td>Winner Talks</td>
        </tr>
        <tr>
          <td>10:30 - 11:00</td>
          <td>Breaks</td>
        </tr>
        <tr>
          <td>11:00 - 11:30</td>
          <td>Invite Talk #3 (Prof. Kris Kitani): Modeling Interacting Humans</td>
        </tr>
        <tr>
          <td>11:30 - 12:00</td>
          <td>Invite Talk #4 (Prof. Angjoo Kanazawa): How to Train Your Humanoid (from Video)</td>
        </tr>
        <tr>
          <td>12:00 - 12:30</td>
          <td>Closing</td>
        </tr>
      </table>
    </section>

    <!-- Global Pose Challenge Section -->
    <section id="challenge">
      <h2>Global Pose Challenge</h2>
      <h3>Overview</h3>
      <p>
        We also host the competition from the <a href="https://inside.fifa.com/innovation/innovation-programme/skeletal-tracking" target="_blank">FIFA Skeletal Tracking Innovation Programme</a>. It features a public training split along with internally prepared validation and test splits. The challenge aims to advance the state-of-the-art in global pose estimation by evaluating submissions on a realistic and practical setting.
      </p>
      <h3>Further Details</h3>
      <p>
        For more information about the challenge, please refer to the <a href="https://inside.fifa.com/innovation/innovation-programme/skeletal-tracking" target="_blank">FIFA's Challenge Page</a> for reference.
      </p>
    </section>

    <!-- Organizers Section -->
    <section id="organizers">
      <h2>Organizers</h2>
      <div class="organizers-carousel">
        <div class="organizer">
          <img src="assets/imgs/avatar_placeholder_1.jpg"/>
          <h3>Tianjian Jiang</h3>
          <p>ETH Zürich</p>
        </div>
        <div class="organizer">
          <img src="assets/imgs/avatar_organizer_kamanuel.jpg"/>
          <h3>Dr. Manuel Kaufmann</h3>
          <p>ETH Zürich</p>
        </div>
        <div class="organizer">
          <img src="assets/imgs/avatar_organizer_jie.jpg"/>
          <h3>Prof. Jie Song</h3>
          <p>ETH Zürich &amp; HKUST</p>
        </div>
        <div class="organizer">
          <img src="assets/imgs/avatar_organizer_soyong.jpg"/>
          <h3>Soyong Shin</h3>
          <p>Carnegie Mellon University</p>
        </div>
        <div class="organizer">
          <img src="assets/imgs/avatar_organizer_jiye.jpg"/>
          <h3>Jiye Lee</h3>
          <p>Seoul National University</p>
        </div>
        <div class="organizer">
          <img src="assets/imgs/avatar_organizer_ye.jpg"/>
          <h3>Dr. Ye Yuan</h3>
          <p>NVIDIA Research</p>
        </div>
        <div class="organizer">
          <img src="assets/imgs/avatar_organizer_chen.jpg"/>
          <h3>Chen Guo</h3>
          <p>ETH Zürich</p>
        </div>
      </div>
    </section>

    <!-- Contact Section -->
    <section id="contact">
      <h2>Contact</h2>
      <p>For further inquiries, please email us at
        <script>
          const u = "tijiang";
          const d = "ethz.ch";
          document.write(`<a href="mailto:${u}@${d}">${u}@${d}</a>`);
        </script>.
      </p>
    </section>
  </div>
</body>
</html>
